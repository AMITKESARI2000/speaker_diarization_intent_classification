{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label classification transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss,CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import *\n",
    "from tqdm import tqdm, trange\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DOCUMENT_CONTENT</th>\n",
       "      <th>DOCUMENT_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Great News to All Vape Lovers Vapefanz has res...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Vaprcase 2 Review: Lifegrabber√¢‚Ç¨‚Ñ¢s Soluti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>i bought 2 boxes and both has 0.8 and 1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>pod Fundamentals Explained vanilla - When rega...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Pretty fun time streaming some VALORANT with m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>√¢≈° √Ø¬∏¬è√∞≈∏¬ê¬¢ TURTLE JUICE √∞≈∏¬ê¬¢√¢≈° ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Dude check out blankz pods. They make a Juul c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Koko prem vape device here√∞≈∏‚Äò‚Ä∞0562220852...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Hero of the day myblu capsules We tell there a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Hello guys im a newbie just upgraded to the dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4840 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TYPE                                   DOCUMENT_CONTENT  DOCUMENT_CLASS\n",
       "0     TRAIN  Great News to All Vape Lovers Vapefanz has res...               2\n",
       "1     TRAIN  Vaprcase 2 Review: Lifegrabber√¢‚Ç¨‚Ñ¢s Soluti...               1\n",
       "2     TRAIN          i bought 2 boxes and both has 0.8 and 1.2               1\n",
       "3     TRAIN  pod Fundamentals Explained vanilla - When rega...               1\n",
       "4     TRAIN  Pretty fun time streaming some VALORANT with m...               2\n",
       "...     ...                                                ...             ...\n",
       "4835  TRAIN  √¢≈° √Ø¬∏¬è√∞≈∏¬ê¬¢ TURTLE JUICE √∞≈∏¬ê¬¢√¢≈° ...               1\n",
       "4836  TRAIN  Dude check out blankz pods. They make a Juul c...               1\n",
       "4837  TRAIN  Koko prem vape device here√∞≈∏‚Äò‚Ä∞0562220852...               1\n",
       "4838  TRAIN  Hero of the day myblu capsules We tell there a...               2\n",
       "4839  TRAIN  Hello guys im a newbie just upgraded to the dr...               0\n",
       "\n",
       "[4840 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load train, test dataset\n",
    "train_filename = \"train_dropdups.csv\"\n",
    "val_filename = \"validation_dropdups.csv\"\n",
    "test_filename = \"test_dropdups.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_filename)\n",
    "df_val = pd.read_csv(val_filename)\n",
    "df_test = pd.read_csv(test_filename)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique content:  True\n",
      "Null values:  False\n",
      "Average sentence length:  36.20702479338843\n",
      "Std deviation sentence length:  25.99536799296542\n"
     ]
    }
   ],
   "source": [
    "print('Unique content: ', df_train['DOCUMENT_CONTENT'].nunique() == df_train.shape[0])\n",
    "print('Null values: ', df_train.isnull().values.any())\n",
    "print('Average sentence length: ', df_train['DOCUMENT_CONTENT'].str.split().str.len().mean())\n",
    "print('Std deviation sentence length: ', df_train['DOCUMENT_CONTENT'].str.split().str.len().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a frequency plot for each category\n",
    "\n",
    "category_counts = {}\n",
    "for doc_type in df_train['DOCUMENT_CLASS']:\n",
    "    if doc_type not in category_counts.keys():\n",
    "        category_counts[doc_type] = 1\n",
    "    else:\n",
    "        category_counts[doc_type] += 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 4.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots()\n",
    "# df_train['DOCUMENT_CLASS'].value_counts().plot(ax=ax, kind='bar')\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "ax = sns.countplot(x='DOCUMENT_CLASS', data=df_train)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Number of comments per class\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4840,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract out data content column and labels\n",
    "X_train = df_train[\"DOCUMENT_CONTENT\"]\n",
    "X_val = df_val[\"DOCUMENT_CONTENT\"]\n",
    "X_test = df_test[\"DOCUMENT_CONTENT\"]\n",
    "y_train = df_train[\"DOCUMENT_CLASS\"].values\n",
    "y_val = df_val[\"DOCUMENT_CLASS\"].values\n",
    "y_test = df_test[\"DOCUMENT_CLASS\"].values\n",
    "\n",
    "# seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting y into one hot vectors like multiclass\n",
    "\n",
    "# encoded_dict = {‘0’:[1,0,0],’1’:[0,1,0], ‘2’:[0,0,1]}\n",
    "num_classes = len(category_counts.keys())\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_val = np.eye(num_classes)[y_val]\n",
    "y_test = np.eye(num_classes)[y_test]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X before cleaning: Vaprcase 2 Review: Lifegrabber√¢‚Ç¨‚Ñ¢s Solution to Protect Pax 2 Vaporizers ...#cannabisnews #cannabis #hemp #CBD\n",
      "Sample X after cleaning: Vaprcase Review Lifegrabber s Solution to Protect Pax Vaporizers cannabisnews cannabis hemp CBD\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "def rm_non_ascii(text):\n",
    "    # remeove non-ascii characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    # remove digits and underscores\n",
    "    text = re.sub(r'[0-9_:\\-\\'\\\"\\[\\]?/+=.,;!@#$%^&*()<>|{}~]+',' ', text)\n",
    "    # removes mutiple spaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "print(\"Sample X before cleaning:\", X_train[1])\n",
    "X_train = X_train.apply(rm_non_ascii)\n",
    "X_val = X_val.apply(rm_non_ascii)\n",
    "X_test = X_test.apply(rm_non_ascii)\n",
    "print(\"Sample X after cleaning:\", X_train[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X before stemming: Vaprcase Review Lifegrabber s Solution to Protect Pax Vaporizers cannabisnews cannabis hemp CBD\n",
      "Sample X after stemming: Vaprcase Review Lifegrabber s Solution to Protect Pax Vaporizers cannabisnews cannabis hemp CBD\n"
     ]
    }
   ],
   "source": [
    "# stemming to bring base word form. lemmatisation not req\n",
    "\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = ps.stem(words[i])\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "        \n",
    "print(\"Sample X before stemming:\", X_train[1])    \n",
    "# X_train = X_train.apply(stemming)\n",
    "# X_val = X_val.apply(stemming)\n",
    "# X_test = X_test.apply(stemming)\n",
    "print(\"Sample X after stemming:\", X_train[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(y_test, y_pred, title=\"Classifier\"):\n",
    "    # Calculate confusion matrix\n",
    "\n",
    "    matrix=confusion_matrix(y_test, y_pred)\n",
    "    cm_labeled=pd.DataFrame(matrix,index=['0','1','2'],columns=['0','1','2'])\n",
    "    # True Labels in y-axis/rows. Precision = TP/(TP+FP)\n",
    "#     print(\"Confusion Matrix:\\n\", cm_labeled)\n",
    "    sns.heatmap(cm_labeled, annot=True)\n",
    "    plt.show()\n",
    "\n",
    "    # Get the accuracy\n",
    "    print('\\nAccuracy: {:.5f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    # Print the classification report\n",
    "    print(f'Classification Report {title}:')\n",
    "#     TODO fix target names dynamic\n",
    "    print(classification_report(y_test, y_pred, target_names=['DOC_0', 'DOC_1', 'DOC_2']))\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.tolist()\n",
    "X_val = X_val.values.tolist()\n",
    "X_test = X_test.values.tolist()\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/root/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# tokenizer converts sentence words into vector of fixed size numbers. Adding <Start> and <End> tag as well\n",
    "\n",
    "max_length = 200\n",
    "# TODO: or 100\n",
    "# BERT tokenizer.\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# # XLNet tokenizer\n",
    "# tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
    "# # RoBERTa tokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
    "# DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# MPNet\n",
    "# tokenizer = MPNetTokenizer.from_pretrained(\"microsoft/mpnet-base\")\n",
    "# MiniLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-electra-base')\n",
    "# DeBERTa\n",
    "# tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "# DeBERTa v2\n",
    "# tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "# Electra HF\n",
    "# tokenizer = ElectraTokenizer.from_pretrained(\"bhadresh-savani/electra-base-emotion\")\n",
    "# Elctra Cross enocder\n",
    "# tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-electra-base')\n",
    "\n",
    "# tokenizer's encoding method\n",
    "encodings_X_train = tokenizer.batch_encode_plus(X_train,max_length=max_length,pad_to_max_length=True, return_token_type_ids=True)\n",
    "encodings_X_val = tokenizer.batch_encode_plus(X_val,max_length=max_length,pad_to_max_length=True, return_token_type_ids=True)\n",
    "encodings_X_test = tokenizer.batch_encode_plus(X_test,max_length=max_length,pad_to_max_length=True, return_token_type_ids=True)\n",
    "\n",
    "print('tokenizer outputs: ', encodings_X_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaprcase Review Lifegrabber s Solution to Protect Pax Vaporizers cannabisnews cannabis hemp CBD  \n",
      "[0. 1. 0.] --->\n",
      "\n",
      "input encoding : [101, 12436, 18098, 18382, 3319, 2166, 17643, 29325, 1055, 5576, 2000, 4047, 6643, 2595, 20064, 17629, 2015, 17985, 2638, 9333, 17985, 19610, 2361, 17324, 2094, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token type ids : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# train tokenized embeddings and masks\n",
    "input_ids_X_train = encodings_X_train['input_ids'] # tokenized and encoded sentences\n",
    "token_type_ids_X_train = encodings_X_train['token_type_ids'] # token type ids\n",
    "attention_masks_X_train = encodings_X_train['attention_mask'] # attention masks\n",
    "\n",
    "# validation tokenized embeddings and masks\n",
    "input_ids_X_val = encodings_X_val['input_ids']\n",
    "token_type_ids_X_val = encodings_X_val['token_type_ids'] \n",
    "attention_masks_X_val = encodings_X_val['attention_mask'] \n",
    "\n",
    "# test tokenized embeddings and masks\n",
    "input_ids_X_test = encodings_X_test['input_ids']\n",
    "token_type_ids_X_test = encodings_X_test['token_type_ids'] \n",
    "attention_masks_X_test = encodings_X_test['attention_mask']\n",
    "\n",
    "\n",
    "print(f\"{X_train[1]}  \\n{y_train[1]} --->\\n\\ninput encoding : {input_ids_X_train[1]}\\ntoken type ids : {token_type_ids_X_train[1]}\\nattention mask : {attention_masks_X_train[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_697/84025241.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids_X_train = torch.tensor(input_ids_X_train)\n",
      "/tmp/ipykernel_697/84025241.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks_X_train = torch.tensor(attention_masks_X_train)\n",
      "/tmp/ipykernel_697/84025241.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n",
      "/tmp/ipykernel_697/84025241.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_type_ids_X_train = torch.tensor(token_type_ids_X_train)\n",
      "/tmp/ipykernel_697/84025241.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids_X_val = torch.tensor(input_ids_X_val)\n",
      "/tmp/ipykernel_697/84025241.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks_X_val = torch.tensor(attention_masks_X_val)\n",
      "/tmp/ipykernel_697/84025241.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val = torch.tensor(y_val)\n",
      "/tmp/ipykernel_697/84025241.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_type_ids_X_val = torch.tensor(token_type_ids_X_val)\n",
      "/tmp/ipykernel_697/84025241.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids_X_test = torch.tensor(input_ids_X_test)\n",
      "/tmp/ipykernel_697/84025241.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_masks_X_test = torch.tensor(attention_masks_X_test)\n",
      "/tmp/ipykernel_697/84025241.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test)\n",
      "/tmp/ipykernel_697/84025241.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_type_ids_X_test = torch.tensor(token_type_ids_X_test)\n"
     ]
    }
   ],
   "source": [
    "# Select a batch size for training. For fine-tuning with XLNet, recommend a batch size of 32, 48, or 128.\n",
    "batch_size = 32\n",
    "\n",
    "# Convert all of our data into torch tensors\n",
    "# train\n",
    "input_ids_X_train = torch.tensor(input_ids_X_train)\n",
    "attention_masks_X_train = torch.tensor(attention_masks_X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "token_type_ids_X_train = torch.tensor(token_type_ids_X_train)\n",
    "\n",
    "# validation\n",
    "input_ids_X_val = torch.tensor(input_ids_X_val)\n",
    "attention_masks_X_val = torch.tensor(attention_masks_X_val)\n",
    "y_val = torch.tensor(y_val)\n",
    "token_type_ids_X_val = torch.tensor(token_type_ids_X_val)\n",
    "\n",
    "# test\n",
    "input_ids_X_test = torch.tensor(input_ids_X_test)\n",
    "attention_masks_X_test = torch.tensor(attention_masks_X_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "token_type_ids_X_test = torch.tensor(token_type_ids_X_test)\n",
    "\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, \n",
    "# unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory\n",
    "train_data = TensorDataset(input_ids_X_train, attention_masks_X_train, y_train, token_type_ids_X_train)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(input_ids_X_val, attention_masks_X_val, y_val, token_type_ids_X_val)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create test dataloader\n",
    "test_data = TensorDataset(input_ids_X_test, attention_masks_X_test, y_test, token_type_ids_X_test)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# save the dataloader\n",
    "torch.save(train_dataloader,'train_data_loader')\n",
    "torch.save(validation_dataloader,'validation_data_loader')\n",
    "torch.save(test_dataloader,'test_data_loader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model & Set Params\n",
    "\n",
    "# (batch_size, epoch, accuracy)\n",
    "# BERT (128,20, 0.801)\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_classes)\n",
    "# XLNet: (32, 12, 0.799)\n",
    "# model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_classes)\n",
    "# RoBERTa: (64, 32, 0.8001)\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_classes)\n",
    "# DistillBERT (128, 50, 0.7994)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_classes)\n",
    "# MPNet (128,6,0.81010)\n",
    "# model = MPNetForSequenceClassification.from_pretrained(\"microsoft/mpnet-base\", num_labels=num_classes)\n",
    "# MiniLM (48, 16, 0.8028)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2',ignore_mismatched_sizes=True, num_labels=num_classes)\n",
    "# deBERTa (32, 36, 0.8185)\n",
    "# model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=num_classes)\n",
    "# deBERTa v2\n",
    "# model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v2-xlarge\", num_labels=num_classes)\n",
    "# Electra HF(128, 16, 0.8004)\n",
    "# model = ElectraForSequenceClassification.from_pretrained(\"bhadresh-savani/electra-base-emotion\", ignore_mismatched_sizes=True, num_labels=num_classes)\n",
    "# Electra Cross encoder (64, 16, 0.80889)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-electra-base', ignore_mismatched_sizes=True, num_labels=num_classes)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "# print(\"named parameters: \", param_optimizer)\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True, )\n",
    "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimizat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 10.57 GiB already allocated; 6.44 MiB free; 10.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# # Forward pass for multiclass classification\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# loss = outputs[0]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# logits = outputs[1]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Forward pass for multilabel classification\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss() \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:747\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 747\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    757\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:567\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:345\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    343\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 345\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:283\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    292\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:211\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    208\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    209\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim_per_head\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    213\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(mask_reshp)\u001b[38;5;241m.\u001b[39mexpand_as(scores)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 10.57 GiB already allocated; 6.44 MiB free; 10.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# use “Binary Cross Entropy With Logits” as our loss function\n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 2\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "\n",
    "  # Tracking variables\n",
    "  tr_loss = 0 #running loss\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # # Forward pass for multiclass classification\n",
    "    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    # loss = outputs[0]\n",
    "    # logits = outputs[1]\n",
    "\n",
    "    # Forward pass for multilabel classification\n",
    "    outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    loss_func = BCEWithLogitsLoss() \n",
    "    loss = loss_func(logits.view(-1,num_classes),b_labels.type_as(logits).view(-1,num_classes)) #convert labels to float for calculation\n",
    "#     loss_func = BCELoss() \n",
    "#     loss_func = CrossEntropyLoss() \n",
    "#     loss = loss_func(torch.sigmoid(logits.view(-1,num_classes)),b_labels.type_as(logits).view(-1,num_classes)) #convert labels to float for calculation\n",
    "    train_loss_set.append(loss.item())    \n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Variables to gather full output\n",
    "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "  # Predict\n",
    "  for i, batch in enumerate(validation_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "      b_logit_pred = outs[0]\n",
    "      pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "      pred_label = pred_label.to('cpu').numpy()\n",
    "      b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "  # Flatten outputs\n",
    "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "  true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "  # Calculate Accuracy\n",
    "  threshold = 0.50\n",
    "#   pred_bools = [pl>threshold for pl in pred_labels]\n",
    "#   true_bools = [tl==1 for tl in true_labels]\n",
    "  pred_bools = [np.argmax(pl, axis=0) for pl in pred_labels]    \n",
    "  true_bools = [np.argmax(pl, axis=0) for pl in true_labels]\n",
    "\n",
    "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func(logits.view(-1,num_classes),b_labels.type_as(logits).view(-1,num_classes)) #convert labels to float for calculation\n",
    "# logits.view(-1, num_classes)\n",
    "# b_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# output_dir = 'model_save'\n",
    "\n",
    "# # Create output directory if needed\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "# model_path = os.path.join(os.getcwd(), output_dir, 'deberta_model_slc')\n",
    "\n",
    "# ## for loading back\n",
    "# # model = model_class.from_pretrained(output_dir)\n",
    "\n",
    "\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# # current accuracy =0.8185 deberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model and Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# Put model in evaluation mode to evaluate loss on the validation set\n",
    "model.eval()\n",
    "\n",
    "#track variables\n",
    "logit_preds, true_labels, pred_labels, tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "  with torch.no_grad():\n",
    "    # Forward pass\n",
    "    outs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    b_logit_pred = outs[0]\n",
    "    pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "    pred_label = pred_label.to('cpu').numpy()\n",
    "    b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "  tokenized_texts.append(b_input_ids)\n",
    "  logit_preds.append(b_logit_pred)\n",
    "  true_labels.append(b_labels)\n",
    "  pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting flattened binary values to boolean values\n",
    "# true_bools = [tl==1 for tl in true_labels]\n",
    "# pred_bools = [pl>0.60 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# get back single value labels from one-hot encoding\n",
    "y_pred = [np.argmax(pl, axis=0) for pl in pred_labels]\n",
    "y_testl = [np.argmax(pl, axis=0) for pl in true_labels]\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(y_testl, y_pred,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(y_testl, y_pred),'\\n')\n",
    "clf_report = classification_report(y_testl,y_pred,target_names=['0','1','2'])\n",
    "\n",
    "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    labels = batch[\"label\"]\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "    loss, _ = self.model(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "\n",
    "    tqdm_dict = {\"train_loss\": loss}\n",
    "    output = OrderedDict({\n",
    "        \"loss\": loss,\n",
    "        \"progress_bar\": tqdm_dict,\n",
    "        \"log\": tqdm_dict\n",
    "        })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    param_optimizer = list(self.model.named_parameters())\n",
    "    no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay_rate\": 0.01\n",
    "                },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay_rate\": 0.0\n",
    "                },\n",
    "            ]\n",
    "    optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=2e-5,\n",
    "            )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
